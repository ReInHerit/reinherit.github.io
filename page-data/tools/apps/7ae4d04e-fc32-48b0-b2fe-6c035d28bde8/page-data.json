{"componentChunkName":"component---src-templates-toolkit-js","path":"/tools/apps/7ae4d04e-fc32-48b0-b2fe-6c035d28bde8","result":{"data":{"markdownRemark":{"html":"<p><strong>Face-fit</strong> follows the idea of the Toolkit's <a href=\"https://reinherit-hub.eu/tools/apps/5f367b50-4089-4718-9b66-8114962c6596\">Strike-a-pose</a> app, i.e. asking the user to <strong>replicate an artwork</strong>, but concentrating on <strong>facial expressions</strong> that require a much more refined matching. </p>\n<p>This application can be used on a <strong>mobile phone</strong> or on a PC, but due to technical limitations of some required computer vision libraries the <strong>Javascript</strong> version for mobile phones need to relieve some image processing functionality to a server. For this reason the app has been developed using two codebases: a <strong>Javascript</strong> one, with <strong>TensorflowJS</strong>, for mobile phones and a <strong>Python</strong> version using <strong>OpenCV</strong> and Tensorflow for the desktop app for museum installations. </p>\n<p><img src=\"https://ucarecdn.com/e95fef8f-d1f8-42c9-88df-ffa74a956876/\" alt=\"Face-Fit App Interface  \" title=\"Face-Fit App Interface  \"></p>\n<blockquote>\n<p><em>Face-Fit App Interface</em></p>\n</blockquote>\n<p>The application asks the users to <strong>replicate the pose</strong> of the <strong>head</strong> and the <strong>expression</strong> of some <strong>portraits</strong> by famous painters and transfer the face of the user on the artworks, generating a new image. The application was designed through a usability study carried out following an iterative design approach with three groups of 5 people. The user places himself in front of the <strong>smartphone or installation equipped with a camera</strong>. He is presented with a series of portraits' paintings in a vertical carousel. The user can choose the artwork to match. At that point the application presents a ghost image of the user's face that the user must try to super-impose on that of the painting to find a perfect match, see following figure.</p>\n<p>App doesn’t ask for personal data, no logging of personal data, performing as much as possible computation on end-user devices, as explained in the <strong>Privacy Policy .</strong></p>\n<p><img src=\"https://ucarecdn.com/8901ee1f-fc4c-449b-bbdd-8532543e038f/\" alt=\"Face-Fit - Privacy Policy\" title=\"Face-Fit - Privacy Policy\"></p>\n<blockquote>\n<p><em>Face-Fit -</em>  <em>Privacy Policy</em></p>\n</blockquote>\n<p>The <strong>ghost image solution</strong> was the result of our usability study which solved some issues related to how to keep the user at the same time concentrated on the task without losing the fun of the game. At first, in fact, we had provided some visual suggestions to find the right pose but they distracted the user from the painting and therefore from the game.</p>\n<p><img src=\"https://ucarecdn.com/ae2eaee6-9357-49b2-b41e-1cea3fa951ce/\" alt=\"User interaction\" title=\"User interaction\"></p>\n<blockquote>\n<p><em>User interaction: the ghost image gives feedback to the user to change his pose and expression to better match that of the artwork.</em> <em>The “ghost” image is the face of the user superimposed on the artwork.</em></p>\n</blockquote>\n<p>A faster than real-time face mesh prediction network is used to obtain 468 3D points for each face, also when using mobile phones.  The points are used to compute the pose of the whole face. Once the pose is matched, the position of eyes, eyebrows and mouth is matched. When both pose and facial expression match, the face of the user is substituted to that of the painting and the description of the artwork is provided. </p>\n<p>Once the pose is matched the user obtains <strong>information on the artwork</strong> and can download the <strong>generated images for sharing on social networks.</strong> By entering your email, the system automatically sends images and in-depth content about the artworks managed by the museum. The user's data and email are not stored and are deleted from the system as soon as the email is sent, in accordance with User Data privacy.</p>\n<p><img src=\"https://ucarecdn.com/88a65fb9-6b1e-497a-8d81-cd68f2bdd79f/\" alt=\"In-depth content and generated images sent via email for sharing on social networks.\" title=\"In-depth content and generated images sent via email for sharing on social networks.\"></p>\n<blockquote>\n<p><em>In-depth content and generated images sent via email for sharing on social networks.</em></p>\n</blockquote>\n<p><strong>Museum</strong> is able to access the <strong>Admin Dashboard</strong>  adding the artworks interacted with by users, and managing content associated with the artwork and to share with the user for more in-depth analysis of the artworks.</p>\n<p><img src=\"https://ucarecdn.com/998cd54f-7045-40c4-81e4-41dd637b929d/\" alt=\"Face Fit - Admin Dashboard\" title=\"Face Fit - Admin Dashboard\"></p>\n<blockquote>\n<p><em>Face Fit - Admin Dashboard</em></p>\n</blockquote>\n<p>Differently from Strike-a-pose the mobile version of the Face-fit application has some differences from the stand-alone version. This is due to the need to use some OpenCV  functions, to perform the color correction of the images that allow to change the style of the images captured from the webcam to the style of the painting, that are not available in Javascript. This has required to implement these functionalities as RESTful APIs in Python, while the frontend is implemented in Javascript with Tensorflow JS, porting the Python code of the standalone version. </p>\n<p>The Face Mesh neural network used is based on a MobileNetV2 architecture that can run in real-time also on mid-level mobile phones.</p>\n<h3><strong>Usage Example</strong></h3>\n<p>App requires a server to host the mobile app and to provide the RESTful APIs of the backend. A QR code can be used to avoid typing the URL of the web apps.</p>\n<h3>**\\</h3>\n<p>Guidelines for reuse**</p>\n<p>The simplest type of reuse is substituting the selected sample artworks with those of the collection of the museum/organization that desires to customize the apps, along with the associated information. Setup of the apps is based on Docker, to simplify the installation of the backend. </p>\n<p>It is possible to extend the apps introducing new types of challenges, e.g. combining classes of artowks in Face-fit as it is done in Strike-a-pose, creating collections of artworks according to some criterion. The challenges of Strike-a-pose can be changed to follow some other criterion other than using full/upper/lower body parts, e.g. according to styles or time. </p>\n<p>Changing the GUIs is relatively easy, since it is needed to update the HTML5 of Strike-a-pose or the Kivy code of Face-fit.</p>\n<h3><strong>Source code</strong></h3>\n<p><strong>Free Codes of the App are available here:</strong><br>\n<a href=\"https://github.com/ReInHerit/strike-a-pose\">https://github.com/ReInHerit/strike-a-pose</a></p>\n<h3>Demo</h3>\n<p><strong>Demo</strong> is available at this link:<br>\n<a href=\"https://reinherit-facefit.herokuapp.com/\">https://reinherit-facefit.hero​kuapp.com</a> </p>\n<p>For more information and support contact <a href=\"\">marco.bertini@unifi.it  </a>MICC - <a href=\"http://www.micc.unifi.it\">Media Integration and Communication Center</a>, University of Florence,  Italy</p>\n<p>\n        <div class=\"embedVideo-container\">\n            <iframe\n              title=\"\"\n              width=\"560\"\n              height=\"316\"\n              src=\"https://www.youtube.com/embed/GHgBIRXqKK8?rel=0\"\n              class=\"embedVideo-iframe\"\n              style=\"border:0\"\n              \n              loading=\"eager\"\n              allowfullscreen\n\t      sandbox=\"allow-same-origin allow-scripts allow-popups\"\n            ></iframe>\n        </div></p>","frontmatter":{"date":"March 03, 2023","title":"Face-Fit","mainReference":null,"type":"toolapp","theme":null,"target_audience":["PROFESSIONAL"],"linkedWebinars":["034cd93b-1043-42e9-9f2a-835d03a4e1cc____Artificial Intelligence and Computer Vision for Cultural Heritage","f2a58e91-3c1a-43c0-baeb-45234da1cbce____Engaging Museum Visitors with Gamification Apps"],"linkedToolkitComponents":["755c16fe-ff7b-4635-aede-1919f5c7f28b____Tensorflow Framework","31efbd7b-1693-4a40-8b0a-c3462e69f0f6____Flask framework","304f85a9-0f2f-41c3-9a78-1771fce81e65____Facial expression recognition"],"linkedToolkitApps":null,"desc":null,"pdf":null,"thumbnail":"https://ucarecdn.com/94e6f411-b4ab-4c44-9322-5966136b0ec4/","chatApps":"https://reinherit.zulipchat.com/#narrow/stream/392282-ReInHerit-Applications-and-Toolkit/topic/Face.20Fit"},"id":"4b21302b-8a74-56d2-b512-8edc69ecceb9","excerpt":"Face-fit follows the idea of the Toolkit's Strike-a-pose app, i.e. asking the user to replicate an artwork, but concentrating on facial…"}},"pageContext":{"id":"7ae4d04e-fc32-48b0-b2fe-6c035d28bde8"}},"staticQueryHashes":[]}