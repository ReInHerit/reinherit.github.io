{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p>Content-based image retrieval (CBIR) is a technique used to search and retrieve images from a multimedia database based on their visual content, such as color, texture, shape, or other features. CBIR can be implemented in various ways, depending on the type of data used for the search and the retrieval method.</p>\n<ol>\n<li>\n<p>Image-to-Image Retrieval: Image-to-Image retrieval, also known as query-by-example (QBE), is the most common form of CBIR. In this case, a user provides an input image, and the system searches for other images in the database that are similar in terms of visual content. The system extracts the features from the query image, such as color, texture, or shape, and compares them with the features of the other images in the database. The retrieved images are then ranked according to their similarity with the query image.</p>\n<p><img src=\"https://ucarecdn.com/2db70a08-2030-4c6b-98fa-b7699839a10d/\" alt=\"Example of QBE retrieval\" title=\"Example of QBE retrieval\"></p>\n</li>\n<li>\n<p>Text-to-Image Retrieval: Text-to-Image retrieval involves searching for images in a database based on the text description of the image. In this case, a user provides a text query, such as a keyword or a natural language description, and the system retrieves images that match the query. The system uses natural language processing (NLP) techniques to extract the relevant features from the text query and compares them with the features of the images in the database.</p>\n<p><img src=\"https://ucarecdn.com/7d4fd55e-d54d-4d4f-8db2-41157a6b300d/\" alt=\"\"></p>\n</li>\n<li>\n<p>Combined Image Retrieval (CIR): Combined Image Retrieval (CIR) is a hybrid approach that combines both image-to-image and text-to-image retrieval techniques. In this case, a user provides both an input image and a text description of the image, and the system searches for images in the database that are similar to both the image and the text query. The system extracts features from both the image and the text query and combines them to retrieve the most relevant images.</p>\n</li>\n</ol>\n<p>The ReInHerit toolkit app implements all these types of retrieval. Actually state-of-the-art results have been obtained in the cultural heritage domain on the <a href=\"https://github.com/delchiaro/NoisyArt\">NoisyArt dataset</a>, and in combined image retrieval on the two most common datasets used in this domain. The following image shows how a neural network sees the parts of the image relted to the description of an artwork: the heatmap shows the parts that are considered more related to the main content of the artwork.</p>\n<p><img src=\"https://ucarecdn.com/72085274-3f84-4fcc-b052-ba4c6ad10ff0/\" alt=\" the heatmap shows the parts that are considered more related to the main content of the artwork by a neural network.\" title=\" the heatmap shows the parts that are considered more related to the main content of the artwork by a neural network.\"></p>\n<p>The Smart Lens app uses CBIR as one of the techniques used to recognize artwork details (the other approaches used in Smart Lens are object detection and image classifications)</p>","excerpt":"Content-based image retrieval (CBIR) is a technique used to search and retrieve images from a multimedia database based on their visual…","frontmatter":{"title":"Content-based image retrieval (CBIR)","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"d9376609-c121-41cc-b560-cc3b430bf350","license":"CC BY 2.0","mainReference":null,"thumbnail":null,"tags":null},"wordCount":{"words":421}}},{"node":{"html":"<p><img src=\"\" alt=\"\"></p>\n<p>Face-Fit application has been developed in JavaScript on the client side and in Python on the server side. Pose detection on the human bodies is achieved using TensorflowJS 1 detection API exploiting the pose detection model, MoveNet.</p>\n<p>The model runs completely client-side in the browser. Server-side an SQLLite database is used to stores artworks’collections, challenges and artworks’ metadata and descriptions.</p>\n<p><strong>Free Codes of the App are available here:</strong><br>\n<a href=\"https://github.com/ReInHerit/strike-a-pose\">https://github.com/ReInHerit/strike-a-pose</a></p>","excerpt":"Face-Fit application has been developed in JavaScript on the client side and in Python on the server side. Pose detection on the human…","frontmatter":{"title":"Face Fit - Codes","date":"5 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"ef96fa44-01c9-4e91-b9a5-29f8fadafee4","license":"CC BY 2.0","mainReference":null,"thumbnail":"","tags":null},"wordCount":{"words":72}}},{"node":{"html":"<p><img src=\"\" alt=\"\"></p>\n<p>The application has been developed in JavaScript on the client side and in Python on the server side. Pose detection on the human bodies is achieved using TensorflowJS 1 detection API exploiting the pose detection model, MoveNet. The model runs completely client-side in the browser. Server-side an SQLLite database is used to stores artworks’collections, challenges and artworks’ metadata and descriptions.</p>\n<p><strong>Free Codes of the App are available here:</strong><br>\n<a href=\"https://github.com/ReInHerit/strike-a-pose\">https://github.com/ReInHerit/strike-a-pose</a></p>","excerpt":"The application has been developed in JavaScript on the client side and in Python on the server side. Pose detection on the human bodies is…","frontmatter":{"title":"Strike a Pose - Codes","date":"5 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"aa5e9102-0b65-41f6-bd85-f5c946b7ea96","license":"CC BY 2.0","mainReference":null,"thumbnail":"","tags":null},"wordCount":{"words":72}}},{"node":{"html":"<p>Django is a powerful and popular web application framework for Python that is designed to make web development easier, faster, and more secure.</p>\n<p>Django provides a full-stack framework for building web applications, which means that it includes everything you need to build a complete and robust web application, from handling user requests to managing the database and rendering HTML templates.</p>\n<p>Django has been used to develop the backend of several apps of the ReInHerit toolkit such as: <strong>Multimedia Chatbot</strong> and <strong>Smart Video Restoration</strong> demo app.</p>","excerpt":"Django is a powerful and popular web application framework for Python that is designed to make web development easier, faster, and more…","frontmatter":{"title":"Django framework","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"1886a679-0213-4c0d-bdeb-989b674a4804","license":"CC BY 2.0","mainReference":null,"thumbnail":"https://upload.wikimedia.org/wikipedia/commons/4/45/Django_logo.png","tags":null},"wordCount":{"words":85}}},{"node":{"html":"<p>Face landmark recognition is the task of detecting and identifying specific points on a human face, such as the corners of the eyes, the tip of the nose, and the corners of the mouth. MediaPipe is a framework for building multimodal machine learning pipelines, which includes a neural network for face landmark recognition.</p>\n<p>The MediaPipe face landmark recognition neural network uses a combination of convolutional neural network (CNN) and regression layers to predict the coordinates of facial landmarks. The network takes as input an image or video frame of a human face and outputs a list of coordinates for each facial landmark.</p>\n<p>The ReInHerit toolkit <strong>Face-fit</strong> app uses the MediaPipe network to understand the pose and expression of users and evaluate how similar they are w.r.t. those depicted in an artwork.</p>\n<p><img src=\"https://ucarecdn.com/11417afc-7068-46cd-ac3d-47fb50c2634f/-/crop/1305x638/283,0/-/preview/\" alt=\"\"></p>","excerpt":"Face landmark recognition is the task of detecting and identifying specific points on a human face, such as the corners of the eyes, the tip…","frontmatter":{"title":"Facial expression recognition","date":"3 months ago","target_audience":["VISITOR"],"layout":null,"type":"toolcomponent","pageId":"304f85a9-0f2f-41c3-9a78-1771fce81e65","license":"CC BY 2.0","mainReference":null,"thumbnail":null,"tags":null},"wordCount":{"words":131}}},{"node":{"html":"<p>Object recognition is the task of identifying objects in an image or video frame. SSD (Single Shot Detector) and MobileNet are two deep learning-based neural network architectures that can be used for object recognition.</p>\n<p>MobileNet is a lightweight neural network architecture designed to run efficiently on mobile and edge devices. It uses depthwise separable convolutions to reduce the number of parameters and computational complexity while maintaining high accuracy. SSD is a single-shot detection neural network architecture that predicts object bounding boxes and class probabilities directly from input images.</p>\n<p>When combined, SSD/MobileNet becomes a powerful object recognition system that can run in real-time on mobile and edge devices. The MobileNet backbone is used to extract features from the input image, while the SSD head is used to predict object bounding boxes and class probabilities.</p>\n<p>The SSD/MobileNet network is trained on a large dataset of annotated images, which is used to learn the relationships between image features and object classes. During inference, the network takes an input image and outputs a list of predicted object bounding boxes and their corresponding class probabilities.</p>\n<p>For these computational capabilities a SSD/Mobilenet object detector has been used in the ReInHerit toolkit Smart Lens app (the app can use also CBIR and image classification) to recognize artwork details.</p>\n<p><img src=\"https://ucarecdn.com/7c6f8edb-150d-4bda-83fa-3fe2d6a2f03a/-/crop/824x1345/4,89/-/preview/\" alt=\"Example of object detection in Smart Lens\" title=\"Example of object detection in Smart Lens\"></p>","excerpt":"Object recognition is the task of identifying objects in an image or video frame. SSD (Single Shot Detector) and MobileNet are two deep…","frontmatter":{"title":"Object recognition","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"3e558c0d-e46e-4a06-ba9a-049caa8f66bb","license":"CC BY 2.0","mainReference":null,"thumbnail":null,"tags":null},"wordCount":{"words":221}}},{"node":{"html":"<p>Flask is a lightweight and easy-to-use web application framework for Python. Flask allows developers to quickly create web applications with minimal setup and boilerplate code. It provides a simple and flexible structure for building web applications that can be easily extended and customized.</p>\n<p>With Flask, it is possible to easily define the routes for web application, handle user input and requests, and render HTML templates for displaying content to users. Flask also provides support for working with databases, managing user authentication and sessions, and integrating with other web technologies such as JavaScript and CSS.</p>\n<p>Several backends of ReInHerit toolkit apps have been developed using Flask, such as <strong>Strike-a-pose</strong> and <strong>Face-fit</strong>.</p>","excerpt":"Flask is a lightweight and easy-to-use web application framework for Python. Flask allows developers to quickly create web applications with…","frontmatter":{"title":"Flask framework","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"31efbd7b-1693-4a40-8b0a-c3462e69f0f6","license":"CC BY 2.0","mainReference":null,"thumbnail":"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Flask_logo.svg/460px-Flask_logo.svg.png","tags":null},"wordCount":{"words":110}}},{"node":{"html":"<p><a href=\"https://pytorch.org\">PyTorch</a> is an open-source machine learning framework developed by Facebook's AI research team. It is a Python-based scientific computing package that allows you to build and train machine learning models for various tasks, such as image and speech recognition, natural language processing, and robotics.</p>\n<p>PyTorch is based on the idea of dynamic computation graphs, which means that the graph is constructed on the fly during the forward pass of the model. This allows for more flexibility and easier debugging compared to static computation graphs used in other frameworks like TensorFlow. With dynamic computation graphs, you can use Python control flow statements, such as loops and conditionals, to build complex models.</p>\n<p>This framework has been used in several apps of the ReInHerit toolkit, typically those where the backend provides the main deep learning functionalities such as <strong>Smart Video Restoration</strong>, <strong>Smart Retrieval</strong> and the <strong>Multimedia Chatbot</strong>.</p>","excerpt":"PyTorch is an open-source machine learning framework developed by Facebook's AI research team. It is a Python-based scientific computing…","frontmatter":{"title":"PyTorch Framework","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"f682c5c9-46e5-4c15-bf52-21d5f76a935f","license":"CC BY 2.0","mainReference":null,"thumbnail":"https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png","tags":null},"wordCount":{"words":144}}},{"node":{"html":"<p>Fine-tuning a neural network involves taking a pre-trained neural network that has already been trained on a large dataset and using it as a starting point to train on a new, smaller dataset. The pre-trained neural network has already learned to recognize general patterns in the original dataset, and fine-tuning involves adjusting the parameters of the neural network to improve its performance on the new, smaller dataset.</p>\n<p>A typical use case in cultural heritage is to improve the performance of networks that are typically trained on photos of real-worlkd objects and not on artistic depictions (e.g. paintings or statues). This may be necessary to recognize objects, perform content-based image retrieval or classify visual content.</p>\n<p><img src=\"https://ucarecdn.com/90bcb1fa-14de-460f-bdd4-5b18c9d32369/\" alt=\"Example of results using fine-tuning\" title=\"Example of results using fine-tuning\"></p>\n<p>In the ReInHerit toolkit a specific web-based application has been developed to train the neural networks used in the SmartLens application. The image shows how fine tuning an object detection network on paintings helps to recognize many more objects than using a neural network trained on photos of persons !</p>\n<p>In general, fine-tuning typically involves two stages:</p>\n<ol>\n<li>Feature extraction: In this stage, the pre-trained neural network is used as a feature extractor. The input data is passed through the pre-trained neural network, and the output of one or more intermediate layers is used as features for a new, smaller neural network. The new neural network is then trained on the new, smaller dataset to perform a specific task, such as classification or regression.</li>\n<li>Fine-tuning: In this stage, the pre-trained neural network is further trained on the new, smaller dataset. The weights of one or more layers of the pre-trained neural network are modified, while keeping the weights of the other layers fixed. This allows the pre-trained neural network to adapt to the new dataset and improve its performance on the specific task.</li>\n</ol>\n<p>Fine-tuning a neural network has several advantages, including:</p>\n<ol>\n<li>Reduced training time: Fine-tuning a pre-trained neural network can reduce the amount of time required to train a new neural network from scratch, as the pre-trained network has already learned general features that can be used as a starting point.</li>\n<li>Improved performance: Fine-tuning a pre-trained neural network can improve its performance on a specific task, as the network has already learned general patterns in the original dataset.</li>\n<li>Reduced overfitting: Fine-tuning a pre-trained neural network can reduce the risk of overfitting on a small dataset, as the pre-trained network has already learned to generalize from a large dataset.</li>\n</ol>\n<h3>Source code</h3>\n<p>A web-based application for neural network fine tuning is part of the ReInHerit toolkit. The source code is available in the Github of ReInHerit: <a href=\"https://github.com/ReInHerit/reinherit-webnet-trainer\">https://github.com/ReInHerit/reinherit-webnet-trainer</a></p>","excerpt":"Fine-tuning a neural network involves taking a pre-trained neural network that has already been trained on a large dataset and using it as a…","frontmatter":{"title":"Neural Network Fine-tuning","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"9de39bcf-0dc4-4248-b1e8-521e0141cf4d","license":"CC BY 2.0","mainReference":null,"thumbnail":null,"tags":null},"wordCount":{"words":435}}},{"node":{"html":"<p>Pose recognition using deep learning involves training deep neural networks to detect and classify human body poses from images or video data.</p>\n<p><a href=\"https://www.tensorflow.org/hub/tutorials/movenet\">MoveNet</a> is a deep learning-based pose estimation framework that uses lightweight models optimized for mobile and edge devices. It is designed to perform real-time and accurate human pose estimation from video or image data. MoveNet is built on the EfficientNet backbone and uses a combination of depthwise separable convolutions and skip connections to extract features and estimate human poses.</p>\n<p>MoveNet comes in different variants: Lightning, and Thunder. Lightning is intended for latency-critical applications, while Thunder is intended for applications that require high accuracy. In the ReInHerit toolkit app <strong>Strike-a-pose</strong> we have used Lightning to eploit its low-latency, required for a better user interaction in a gamification-based app.</p>\n<p><img src=\"https://ucarecdn.com/4d2c90f2-dbbe-40a3-ad56-05170649403f/-/crop/512x524/0,0/-/preview/\" alt=\"Example of Movenet applied to  Mona Lisa painting.\" title=\"Example of Movenet applied to  Mona Lisa painting.\"></p>\n<p>Other possible applications of MoveNet in cultural heritage include pose recognition and analysis of historical artworks and sculptures. MoveNet can be used to estimate the poses of figures depicted in ancient art and compare them to known poses from different historical periods. This analysis can provide insights into the cultural and historical contexts of the artwork and help identify its origin and cultural influences.</p>\n<p>MoveNet can also be used in virtual and augmented reality applications in cultural heritage. For example, MoveNet can be used to track the movements of users in a virtual museum or exhibition, allowing them to interact with digital artifacts and experience cultural heritage in an immersive and interactive way.</p>","excerpt":"Pose recognition using deep learning involves training deep neural networks to detect and classify human body poses from images or video…","frontmatter":{"title":"Pose recognition","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"05f95e69-71ff-418c-a7c6-306de11fc4c3","license":"CC BY 2.0","mainReference":null,"thumbnail":null,"tags":null},"wordCount":{"words":250}}},{"node":{"html":"<p><a href=\"https://www.tensorflow.org\">TensorFlow</a> is an open-source machine learning framework developed by Google. It allows you to build and train machine learning models for various tasks, such as image classification, natural language processing, and regression analysis.</p>\n<p>TensorFlow can be used in mobile and web applications in a variety of ways. In the development of the ReInHerit toolkit we used it in two ways:</p>\n<p><strong>Mobile applications</strong>: TensorFlow provides several tools and libraries that can help you build machine learning models for mobile devices. For example, TensorFlow Lite is a lightweight version of TensorFlow designed for mobile and embedded devices. It allows you to run trained TensorFlow models on mobile devices with low computational resources. We used it in the <strong>Smart Tourism app</strong>.</p>\n<p><strong>Web applications</strong>: TensorFlow can be used to build machine learning models that run in the browser using JavaScript. TensorFlow.js is a JavaScript library that allows you to run TensorFlow models in the browser or in Node.js. We used it for <strong>Face-fit, Strike-a-pose and Smart Lens apps</strong>.</p>","excerpt":"TensorFlow is an open-source machine learning framework developed by Google. It allows you to build and train machine learning models for…","frontmatter":{"title":"Tensorflow Framework","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolcomponent","pageId":"755c16fe-ff7b-4635-aede-1919f5c7f28b","license":"CC BY 2.0","mainReference":null,"thumbnail":"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/224px-Tensorflow_logo.svg.png","tags":null},"wordCount":{"words":164}}}]}}}