{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p><img src=\"https://ucarecdn.com/cf4dd5aa-770e-4aa3-b26b-d8e0dcb258f5/\" alt=\"\"></p>\n<p>The purpose of the application is to create an immersive audio experience that can be setup at museums. Immersive audio stations are placed in various areas of a museum, offering visitors an interactive experience. Users that enter in the corresponding areas within the museum, based on their behavior (e.g., based on how many people are in the area, or how active they are), trigger specific sounds that are layered together creating a music composition.</p>\n<p>The code for the application can be accessed from the following GitHub repository link: <a href=\"https://github.com/CYENS/Reinherit-Hadjigeorgakis-Kornesios-Mansion\">https://github.com/CYENS/Reinherit-Hadjigeorgakis-Kornesios-Mansion</a>.</p>\n<p>A Technical Manual for the Immersive Performance, to be used to set up a similar performance can be downloaded as a PDF below.</p>","excerpt":"The purpose of the application is to create an immersive audio experience that can be setup at museums. Immersive audio stations are placed…","frontmatter":{"title":"Immersive and Interactive Music Performance","date":"4 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolapp","pageId":"7cbc7084-6711-4ac0-88c6-4e05cc34ae50","license":"CC BY 2.0","thumbnail":"https://ucarecdn.com/dad8926d-b220-4847-a923-7bdfa8aca482/"},"wordCount":{"words":115}}},{"node":{"html":"<p>This application is designed for <strong>cultural smart tourism</strong> and provides functionalities for landmark recognition using <strong>computer vision.</strong> The vision system is able to deal also with large monuments, where only a portion of the landmark is visible, using a specific run-time image augmentation process that is combined with a training-time augmentation.  The smart tourism app is a native <strong>Android app</strong> that provides the basic functionalities. It has been developed as an Android app to overcome the computational limitations of web based systems, that are still not feature complete when using <strong>TensorflowJS</strong> with respect to Tensorflow Lite. Despite this it works also on low and  mid-level devices, since it has been designed to use a set of very fast neural network that can be executed in real-time (based on variations of the MobileNet V3 architecture). The system uses computer vision to recognize <strong>landmarks</strong> and monuments, providing <strong>multimedia information</strong>, and  can be <strong>personalized</strong> to create different tours.</p>\n<p>The <strong>end-user application</strong> is complemented by a set of backend tools that create the set of images needed to recognize landmarks, performing an augmentation that is used both at training time and at test time; these tools are to be used by the creators of the smart guides.</p>\n<p>The vision system implements a <strong>content-based image retrieval (CBIR),</strong> using techniques that are completely different, because of the nature of the task that is addressing landmarks, from that of the Smart Lens app. In fact when considering the recognition of landmarks a common case is that the user does not frame with the lens the whole object, and that the object itself has <strong>many different and possibly diverse views</strong>. To this end when creating the guide the curators must use a <strong>large number of images.</strong> To cope with the variability of the point of view of the users each image is further split in different parts and zoomed in and out versions are created, as shown in the following figures. All these augmentations result in the creation of a very <strong>large dataset of images</strong> representing the landmarks.</p>\n<p><img src=\"https://ucarecdn.com/96cde401-f599-4fdd-84a0-da1ce1b0d742/\" alt=\"image splitting augmentation\" title=\"image splitting augmentation\"></p>\n<blockquote>\n<p><em>Image splitting augmentation</em></p>\n</blockquote>\n<p><img src=\"https://ucarecdn.com/c7afd79a-b476-490b-8754-3bd4d3ec41f9/\" alt=\"image zooming augmentation\" title=\"image zooming augmentation\"></p>\n<blockquote>\n<p><em>Image zooming augmentation</em></p>\n</blockquote>\n<p>To cope with the large number of images, these are indexed using <strong>FAISS</strong>, an indexing library that allows to perform approximate nearest neighbour retrieval, thus reducing the number of actual image comparisons that are needed to determine the landmark that is framed. This need is exacerbated by the fact that we also implement a test-time augmentation, i.e. the image that is taken with the mobile phone is used to generate two zoomed versions, and each image is further split into 3x3. This test-time augmentation is used <strong>to improve the performance of the CBIR system</strong> in terms of accuracy. For each split of each image obtained during the use of the application is computed a descriptor using the MobileNet network, and using FAISS a nearest neighbor image of the database is retrieved and ranked in terms of visual similarity, selecting the 3 most similar images, as shown in the following figure. A K-NN classifier is used to recognize the landmark based on these retrieved images.</p>\n<p><img src=\"https://ucarecdn.com/b2207fb6-2dbd-4560-b4e0-fef415fa1535/\" alt=\"smart tourism app: landmark recognition\" title=\"smart tourism app: landmark recognition\"></p>\n<blockquote>\n<p><em>Smart tourism app: landmark recognition</em></p>\n</blockquote>\n<p>To test the performance of the computer vision system, its accuracy performance was tested on the difficult dataset Paris Revisited dataset, developed by the University of Oxford. This dataset is composed of 5000 images of landmarks; we used ⅔ for training and ⅓ for test.</p>\n<p><img src=\"https://ucarecdn.com/51a9476e-b72d-4a5a-ac99-53d77a3b6262/\" alt=\"Revisited Paris dataset\" title=\"Revisited Paris dataset\"></p>\n<blockquote>\n<p><em>Revisited Paris dataset: for each query image is provide a set of good (dark green), medium (light green) and hard (yellow) images that are associated. A CBIR system should provide the results in these categories in this order.</em></p>\n</blockquote>\n<p>Considering the <strong>computational costs</strong> of the variants of MobileNet V3 tested, the smaller version allows to compute the visual features in 0.006 seconds, making it suitable for low-end devices that do not have much computational capabilities. This at the cost of losing 5 percent points in terms of accuracy. On the other hand mid and high-end devices can use a medium and a large network version, that require 0.023 and 0.038 seconds. Thanks to the use of FAISS, the search of similar images takes a negligible amount of time (0.004 seconds). Once the set of  similar images has been obtained the result of the K-NN classifier is instantaneous. The accuracy of the large network is ~76%, while the medium version obtains ~73% and the smaller one 68%. Using the test-time augmentation improves the performance by 6 points, thus reaching up to 82%, showing the <strong>benefit of this technique.</strong></p>\n<p>The following figure shows screenshots of the <strong>application</strong>, with additional debug information in the first two images, and the recognition of a landmark with the associated information.</p>\n<p><img src=\"https://ucarecdn.com/121572b3-e191-405d-8dbd-212b186d0785/\" alt=\"Smart tourism app\" title=\"Smart tourism app\"></p>\n<p><img src=\"https://ucarecdn.com/5ad89dbe-6707-4aeb-8fe0-957cf4b07ba5/\" alt=\"Smart tourism app\" title=\"Smart tourism app\"></p>\n<blockquote>\n<p><em>Smart tourism app, views of the application: debug information to test the capability to differentiate between visually similar landmarks; debug info on camera setup and neural network inference (using CPU instead of GPU); examples of landmark recognition and information on the recognized landmark.</em></p>\n<h3>Source code</h3>\n<p>The source code of the app is available on the Github of ReInHerit: <a href=\"https://github.com/ReInHerit/SmartTourism\">https://github.com/ReInHerit/SmartTourism</a></p>\n</blockquote>","excerpt":"This application is designed for cultural smart tourism and provides functionalities for landmark recognition using computer vision. The…","frontmatter":{"title":"Smart Tourism App","date":"3 months ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolapp","pageId":"437c8b14-f2c8-4fe6-9162-104d4abbb5b6","license":"CC BY 2.0","thumbnail":"https://ucarecdn.com/4f495df3-8f37-4899-a5c0-6df7d87f6baa/"},"wordCount":{"words":855}}}]}}}