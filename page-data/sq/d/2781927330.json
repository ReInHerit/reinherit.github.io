{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p>The purpose of the application is to create an immersive audio experience that can be setup at museums. Immersive audio stations are placed in various areas of a museum, offering visitors an interactive experience. Users that enter in the corresponding areas within the museum, based on their behavior (e.g., based on how many people are in the area, or how active they are), trigger specific sounds that are layered together creating a music composition.</p>\n<p>The code for the application can be accessed from the following GitHub repository link: <a href=\"https://github.com/CYENS/Reinherit-Hadjigeorgakis-Kornesios-Mansion\">https://github.com/CYENS/Reinherit-Hadjigeorgakis-Kornesios-Mansion</a>.</p>\n<p>A Technical Manual for the Immersive Performance, to be used to set up a similar performance can be downloaded as a PDF below.</p>","excerpt":"The purpose of the application is to create an immersive audio experience that can be setup at museums. Immersive audio stations are placed…","frontmatter":{"title":"Immersive and Interactive Music Performance","date":"a month ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolapp","pageId":"7cbc7084-6711-4ac0-88c6-4e05cc34ae50","mainReference":null,"license":"CC BY 2.0","thumbnail":"https://ucarecdn.com/cf4dd5aa-770e-4aa3-b26b-d8e0dcb258f5/"},"wordCount":{"words":115}}},{"node":{"html":"<p>Strike-a-pose is a <strong>web application</strong> which performs analysis and evaluation of human poses compared to poses present in famous paintings or statues. </p>\n<p>Strike-a-Pose can be made available on the visitors' <strong>smartphone</strong>, following the “<strong>Bring Your Own Device” (BYOD</strong>) approach. The system can be used also in a dedicated environment in a gallery, using a standard PC equipped with a large screen and a camera. The same code base is used for the two setups, easing the maintenance of the application. The goal of having the application executing also on mid-level phones means that there’s no need for powerful workstations in case it is used as an installation.  The design of the interface adapts to the two different modalities, providing both a vertical interface suitable for a mobile phone and a horizontal one for installation and desktop.</p>\n<p>The application exploits a <strong>gamification paradigm</strong> with the <strong>educational</strong> purpose of getting users interested in works of art using fun. Once registered, the user is challenged to reproduce in sequence the poses of some artworks from the museum's collections. The skeleton of both the artwork and the visitor can be displayed on the screen in order to facilitate the user in matching the various points and segments. <strong>Matching the poses</strong> provides the <strong>descriptions of each artwork</strong>. The poses to be matched are organized in sets of challenges, e.g. challenges to replicate poses using the whole body, using only the torso (e.g. to allow also wheelchair users to interact), or any other type of challenge that is considered interesting by the museum curators (e.g. based on thematic collections). Once all the poses have been matched, the application allows the user to g<strong>enerate a video</strong> that can be saved for any <strong>social sharing</strong>. The video shows the user matching process and the overall interactive experience lived at the museum. The basic application can be adapted to provide variations of the gamification, e.g. introducing a competition between different users. An example of screenshots of the basic app are shown in the following figure.</p>\n<p><img src=\"https://ucarecdn.com/3eb026de-153c-49ef-8b1a-83433189b979/\" alt=\"Strike a Pose App for smartphone\" title=\"Strike a Pose App for smartphone\"></p>\n<blockquote>\n<p><em>Strike a Pose App for smartphone. 1) Login. 2-3) The user trying to strike the pose in the painting (playing in “easy\" mode, with visible skeletons). 3) Challenge completed: download the video.</em></p>\n</blockquote>\n<p>The application has been developed in <strong>JavaScript</strong> on the client side and in <strong>Python</strong> on the server side. Pose detection on the human bodies is achieved using <strong>TensorflowJS</strong> detection API exploiting the pose detection model, <strong>MoveNet</strong>. MoveNet is a very fast and accurate model that detects 17 key points of a body. The model is used in the variant “Lightning” intended for latency-critical applications and runs faster than real time (30+ FPS) on most modern desktops, laptops, and phones. The model runs completely client-side in the browser; this allows us to run the whole computer vision task on the device of the user, providing a better user experience thanks to the reduced latency for the pose analysis. Server-side an SQLLite database is used to store artworks' collections, challenges and artworks' metadata and descriptions. Communication between the knowledge-base and the interface is ensured through RESTful APIs developed in Flask. The video is created server side. </p>\n<p>The base interface, implemented in <strong>HTML</strong> can be adapted by different users, maintaining the computer vision functionalities, so as to allow customization by different museums. An example of such customization is shown in the following figures:</p>\n<p><img src=\"https://ucarecdn.com/e33839df-0fef-45ff-878b-062e7e5b94bd/\" alt=\"Customized login screen and challenge selection\" title=\"Customized login screen and challenge selection\"></p>\n<blockquote>\n<p><em>Customized login screen and challenge selection</em></p>\n</blockquote>\n<p><img src=\"https://ucarecdn.com/70e896cc-9511-48f6-bb90-fcd5dc3ab8a5/\" alt=\"Horizontal interface for installations - customized template | Customized end-game screen with informations about the artworks\" title=\"Horizontal interface for installations - customized template | Customized end-game screen with informations about the artworks\"></p>\n<blockquote>\n<p><em>Horizontal interface for installations - customized template \\ Customized end-game screen with informations about the artworks</em></p>\n</blockquote>\n<p><img src=\"https://ucarecdn.com/ae137a2b-f721-4f74-8ea7-fcc86b4a00a4/\" alt=\"Strike-a-pose in a competitive setup. \" title=\"Strike-a-pose in a competitive setup. \"></p>\n<blockquote>\n<p><em>Strike-a-pose in a competitive setup. Two users attempt to complete the same challenge in less time || Strike-a-pose in a competitive setup: results of the challenge for each user.</em></p>\n</blockquote>\n<p><strong>Usage Example</strong><br>\nApp requires a server to host the mobile app and to provide the RESTful APIs of the backend. A QR code can be used to avoid typing the URL of the web apps.</p>\n<p>The application is composed of a <strong>backend</strong> that manages the challenges and a <strong>front-end</strong> that runs on mobile devices. A schema of the <strong>main components</strong> of the <strong>backend and front end</strong>  is shown in the following figures:</p>\n<p><img src=\"https://ucarecdn.com/65a51251-857f-413e-9fa6-f1ce4e42dd8b/\" alt=\"Main components of the backend and front-end of Strike-a-pose\" title=\"Main components of the backend and front-end of Strike-a-pose\"></p>\n<blockquote>\n<p><em>Main components of the backend and front-end of Strike-a-pose</em></p>\n</blockquote>\n<p>The interface is completely written in <strong>HTML5</strong>. The computer vision task of matching the pose of the user with the pose of the artworks of the challenge can be implemented completely using the <strong>Tensorflow JS</strong> executed in the browser. The creation of the video produced upon successful completion of the challenge is performed server-side.  The <strong>backend</strong> implements a RESTful API using Flask, and is fully implemented in Python. This eases the integration of several other libraries to access the database of the challenges, using SQLAlchemy and to create the final videos using OpenCV**.** Challenges are maintained in the DB, e.g. allowing to pick poses that require to use only the upper body (e.g. to allow also people with mobility issues to play) or with full body. </p>\n<p>jQuery and Bootstrap are the main components used to design the interface and provide user interaction with the GUI, Webcam Easy JS allows to connect to the webcam through the browser and Tensorflow JS is the workhorse to implement the computer vision functionalities.</p>\n<p><strong>Usage Example</strong><br>\nApp requires a server to host the mobile app and to provide the RESTful APIs of the backend. A QR code can be used to avoid typing the URL of the web apps.</p>\n<p><strong>Guidelines for reuse</strong><br>\nThe simplest type of reuse is substituting the selected sample artworks with those of the collection of the museum/organization that desires to customize the apps, along with the associated information. Setup of the apps is based on Docker, to simplify the installation of the backend. </p>\n<p>It is possible to extend the apps introducing new types of challenges, e.g. combining classes of artworks, creating collections of artworks according to some criterion. The challenges of Strike-a-pose can be changed to follow some other criterion other than using full/upper/lower body parts, e.g. according to styles or time. </p>\n<p>Changing the GUIs is relatively easy, since it is needed to update the HTML5 of Strike-a-pose or the Kivy code of Face-fit.</p>\n<p><strong>Free Codes of the App are available here:</strong></p>\n<p><a href=\"https://github.com/ReInHerit/strike-a-pose\">https://github.com/ReInHerit/strike-a-pose</a></p>\n<p>For more information and support contact <a href=\"\">marco.bertini@unifi.it  </a>MICC - <a href=\"http://www.micc.unifi.it\">Media Integration and Communication Cente</a>r, University of Florence,  Italy</p>\n<p>\n        <div class=\"embedVideo-container\">\n            <iframe\n              title=\"\"\n              width=\"560\"\n              height=\"316\"\n              src=\"https://www.youtube.com/embed/GHgBIRXqKK8?rel=0\"\n              class=\"embedVideo-iframe\"\n              style=\"border:0\"\n              \n              loading=\"eager\"\n              allowfullscreen\n\t      sandbox=\"allow-same-origin allow-scripts allow-popups\"\n            ></iframe>\n        </div></p>","excerpt":"Strike-a-pose is a web application which performs analysis and evaluation of human poses compared to poses present in famous paintings or…","frontmatter":{"title":"Strike a Pose","date":"a month ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolapp","pageId":"5f367b50-4089-4718-9b66-8114962c6596","mainReference":null,"license":"CC BY 2.0","thumbnail":"https://ucarecdn.com/bde51a50-8ac7-4bf9-aa71-c2699d7c2865/"},"wordCount":{"words":1082}}},{"node":{"html":"<p><strong>Face-fit</strong> follows the idea of the Toolkit's Strike-a-pose app, i.e. asking the user to <strong>replicate an artwork</strong>, but concentrating on <strong>facial expressions</strong> that require a much more refined matching. </p>\n<p>This application can be used on a <strong>mobile phone</strong> or on a PC, but due to technical limitations of some required computer vision libraries the <strong>Javascript</strong> version for mobile phones need to relieve some image processing functionality to a server. For this reason the app has been developed using two codebases: a <strong>Javascript</strong> one, with <strong>TensorflowJS</strong>, for mobile phones and a <strong>Python</strong> version using <strong>OpenCV</strong> and Tensorflow for the desktop app for museum installations. </p>\n<p>The application asks the users to <strong>replicate the pose</strong> of the <strong>head</strong> and the <strong>expression</strong> of some <strong>portraits</strong> by famous painters and transfer the face of the user on the artworks, generating a new image. The application was designed through a usability study carried out following an iterative design approach with three groups of 5 people. The user places himself in front of the <strong>smartphone or installation equipped with a camera</strong>. He is presented with a series of portraits' paintings in a vertical carousel. The user can choose the artwork to match. At that point the application presents a ghost image of the user's face that the user must try to super-impose on that of the painting to find a perfect match, see following figure. The <strong>ghost image solution</strong> was the result of our usability study which solved some issues related to how to keep the user at the same time concentrated on the task without losing the fun of the game. At first, in fact, we had provided some visual suggestions to find the right pose but they distracted the user from the painting and therefore from the game.</p>\n<p><img src=\"https://ucarecdn.com/3e19b8d3-0538-4dd9-8a4e-9126716c9a2d/\" alt=\"Face-Fit App for museum installation: select an image.\" title=\"Face-Fit App for museum installation: select an image.\"></p>\n<blockquote>\n<p><em>Face-Fit App for museum installation: select an image.</em></p>\n</blockquote>\n<p>A faster than real-time face mesh prediction network is used to obtain 468 3D points for each face, also when using mobile phones. </p>\n<p>The points are used to compute the pose of the whole face. Once the pose is matched, the position of eyes, eyebrows and mouth is matched. When both pose and facial expression match, the face of the user is substituted to that of the painting and the description of the artwork is provided. </p>\n<p>Once the pose is matched the user obtains <strong>information on the artwork</strong> and can download the <strong>generated images for sharing on social networks.</strong></p>\n<p><img src=\"https://ucarecdn.com/5c4e2f99-3766-4bd5-b1e9-50b05cf7fb8c/\" alt=\"User interaction\" title=\"User interaction\"></p>\n<blockquote>\n<p><em>User interaction: the ghost image gives feedback to the user to change his pose and expression to better match that of the artwork.</em></p>\n</blockquote>\n<p><img src=\"https://ucarecdn.com/027a1033-e3e7-400c-9de1-a37fd0a2b39a/\" alt=\"Matching the pose\" title=\"Matching the pose\"></p>\n<blockquote>\n<p><em>Matching the pose and expression with Leonardo’s Salvator Mundi and generation of the image merging the user face in the artwork. The image is emailed with info on artwork to the user.</em></p>\n</blockquote>\n<p>Differently from Strike-a-pose the mobile version of the Face-fit application has some differences from the stand-alone version. This is due to the need to use some OpenCV  functions, to perform the color correction of the images that allow to change the style of the images captured from the webcam to the style of the painting, that are not available in Javascript. This has required to implement these functionalities as RESTful APIs in Python, while the frontend is implemented in Javascript with Tensorflow JS, porting the Python code of the standalone version. </p>\n<p>The Face Mesh neural network used is based on a MobileNetV2 architecture that can run in real-time also on mid-level mobile phones.</p>\n<p><img src=\"https://ucarecdn.com/3e9e0cd6-a941-4c16-aae2-b09d1cd58e8f/\" alt=\"The “ghost” image \t\" title=\"The “ghost” image\"></p>\n<blockquote>\n<p><em>GUI of the mobile version of Face-fit. The “ghost” image is the face of the user superimposed on the artwork.</em></p>\n</blockquote>\n<p><strong>Usage Example</strong><br>\nApp requires a server to host the mobile app and to provide the RESTful APIs of the backend. A QR code can be used to avoid typing the URL of the web apps.</p>\n<p><strong><br>\nGuidelines for reuse</strong><br>\nThe simplest type of reuse is substituting the selected sample artworks with those of the collection of the museum/organization that desires to customize the apps, along with the associated information. Setup of the apps is based on Docker, to simplify the installation of the backend. </p>\n<p>It is possible to extend the apps introducing new types of challenges, e.g. combining classes of artowks in Face-fit as it is done in Strike-a-pose, creating collections of artworks according to some criterion. The challenges of Strike-a-pose can be changed to follow some other criterion other than using full/upper/lower body parts, e.g. according to styles or time. </p>\n<p>Changing the GUIs is relatively easy, since it is needed to update the HTML5 of Strike-a-pose or the Kivy code of Face-fit.</p>\n<p><strong>Free Codes of the App are available here:</strong><br>\n<a href=\"https://github.com/ReInHerit/strike-a-pose\">https://github.com/ReInHerit/strike-a-pose</a></p>\n<p>For more information and support contact <a href=\"\">marco.bertini@unifi.it  </a>MICC - <a href=\"http://www.micc.unifi.it\">Media Integration and Communication Center</a>, University of Florence,  Italy</p>\n<p>\n        <div class=\"embedVideo-container\">\n            <iframe\n              title=\"\"\n              width=\"560\"\n              height=\"316\"\n              src=\"https://www.youtube.com/embed/GHgBIRXqKK8?rel=0\"\n              class=\"embedVideo-iframe\"\n              style=\"border:0\"\n              \n              loading=\"eager\"\n              allowfullscreen\n\t      sandbox=\"allow-same-origin allow-scripts allow-popups\"\n            ></iframe>\n        </div></p>","excerpt":"Face-fit follows the idea of the Toolkit's Strike-a-pose app, i.e. asking the user to replicate an artwork, but concentrating on facial…","frontmatter":{"title":"Face-Fit","date":"a month ago","target_audience":["PROFESSIONAL"],"layout":null,"type":"toolapp","pageId":"7ae4d04e-fc32-48b0-b2fe-6c035d28bde8","mainReference":null,"license":"CC BY 2.0","thumbnail":"https://ucarecdn.com/94e6f411-b4ab-4c44-9322-5966136b0ec4/"},"wordCount":{"words":798}}}]}}}